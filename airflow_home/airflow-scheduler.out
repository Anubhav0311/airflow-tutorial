[2025-03-31T19:28:42.227+0000] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2025-03-31T19:28:42.259+0000] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2025-03-31T19:28:42.260+0000] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2025-03-31T19:28:42.265+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 16493
[2025-03-31T19:28:42.267+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-31T19:28:42.269+0000] {settings.py:63} INFO - Configured default timezone UTC
[2025-03-31T19:28:42.293+0000] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-03-31T19:33:36.288+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_branching_dag to 2025-03-31 00:00:00+00:00, run_after=2025-04-01 00:00:00+00:00
Dag run  in running state
Dag information Queued at: 2025-03-31 19:33:36.279718+00:00 hash info: 2bf1977cad3ae3d20948e7fe3b244d22
[2025-03-31T19:33:37.481+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: conditional_branching_dag.check_data scheduled__2025-03-30T00:00:00+00:00 [scheduled]>
[2025-03-31T19:33:37.481+0000] {scheduler_job_runner.py:507} INFO - DAG conditional_branching_dag has 0/16 running and queued tasks
[2025-03-31T19:33:37.482+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: conditional_branching_dag.check_data scheduled__2025-03-30T00:00:00+00:00 [scheduled]>
[2025-03-31T19:33:37.483+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: conditional_branching_dag.check_data scheduled__2025-03-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-31T19:33:37.484+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='conditional_branching_dag', task_id='check_data', run_id='scheduled__2025-03-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-03-31T19:33:37.484+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'conditional_branching_dag', 'check_data', 'scheduled__2025-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/first_dag.py']
[2025-03-31T19:33:37.488+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'conditional_branching_dag', 'check_data', 'scheduled__2025-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/first_dag.py']
[2025-03-31T19:33:38.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/airflow-tutorial/airflow_home/dags/first_dag.py
[2025-03-31T19:33:38.982+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-03-31T19:33:38.985+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-03-31T19:33:38.985+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-03-31T19:33:39.240+0000] {task_command.py:467} INFO - Running <TaskInstance: conditional_branching_dag.check_data scheduled__2025-03-30T00:00:00+00:00 [queued]> on host codespaces-6cda86
[2025-03-31T19:33:39.761+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='conditional_branching_dag', task_id='check_data', run_id='scheduled__2025-03-30T00:00:00+00:00', try_number=1, map_index=-1)
[2025-03-31T19:33:39.766+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=conditional_branching_dag, task_id=check_data, run_id=scheduled__2025-03-30T00:00:00+00:00, map_index=-1, run_start_date=2025-03-31 19:33:39.273393+00:00, run_end_date=2025-03-31 19:33:39.381435+00:00, run_duration=0.108042, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=801, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-03-31 19:33:37.482661+00:00, queued_by_job_id=800, pid=18871
[2025-03-31T19:33:39.907+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: conditional_branching_dag.send_alert scheduled__2025-03-30T00:00:00+00:00 [scheduled]>
[2025-03-31T19:33:39.907+0000] {scheduler_job_runner.py:507} INFO - DAG conditional_branching_dag has 0/16 running and queued tasks
[2025-03-31T19:33:39.908+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: conditional_branching_dag.send_alert scheduled__2025-03-30T00:00:00+00:00 [scheduled]>
[2025-03-31T19:33:39.909+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: conditional_branching_dag.send_alert scheduled__2025-03-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-31T19:33:39.909+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='conditional_branching_dag', task_id='send_alert', run_id='scheduled__2025-03-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-03-31T19:33:39.909+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'conditional_branching_dag', 'send_alert', 'scheduled__2025-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/first_dag.py']
[2025-03-31T19:33:39.913+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'conditional_branching_dag', 'send_alert', 'scheduled__2025-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/first_dag.py']
[2025-03-31T19:33:41.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/airflow-tutorial/airflow_home/dags/first_dag.py
[2025-03-31T19:33:41.463+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-03-31T19:33:41.466+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-03-31T19:33:41.467+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-03-31T19:33:41.730+0000] {task_command.py:467} INFO - Running <TaskInstance: conditional_branching_dag.send_alert scheduled__2025-03-30T00:00:00+00:00 [queued]> on host codespaces-6cda86
[2025-03-31T19:33:42.177+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='conditional_branching_dag', task_id='send_alert', run_id='scheduled__2025-03-30T00:00:00+00:00', try_number=1, map_index=-1)
[2025-03-31T19:33:42.180+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=conditional_branching_dag, task_id=send_alert, run_id=scheduled__2025-03-30T00:00:00+00:00, map_index=-1, run_start_date=2025-03-31 19:33:41.764106+00:00, run_end_date=2025-03-31 19:33:41.855453+00:00, run_duration=0.091347, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=802, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-03-31 19:33:39.908468+00:00, queued_by_job_id=800, pid=18900
[2025-03-31T19:33:42.319+0000] {dagrun.py:854} INFO - Marking run <DagRun conditional_branching_dag @ 2025-03-30 00:00:00+00:00: scheduled__2025-03-30T00:00:00+00:00, state:running, queued_at: 2025-03-31 19:33:36.279718+00:00. externally triggered: False> successful
Dag run in success state
Dag run start:2025-03-31 19:33:36.298582+00:00 end:2025-03-31 19:33:42.319933+00:00
[2025-03-31T19:33:42.320+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=conditional_branching_dag, execution_date=2025-03-30 00:00:00+00:00, run_id=scheduled__2025-03-30T00:00:00+00:00, run_start_date=2025-03-31 19:33:36.298582+00:00, run_end_date=2025-03-31 19:33:42.319933+00:00, run_duration=6.021351, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-03-30 00:00:00+00:00, data_interval_end=2025-03-31 00:00:00+00:00, dag_hash=2bf1977cad3ae3d20948e7fe3b244d22
[2025-03-31T19:33:42.323+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_branching_dag to 2025-03-31 00:00:00+00:00, run_after=2025-04-01 00:00:00+00:00
[2025-03-31T19:33:42.340+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-31T19:38:42.475+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
